{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Try Two of Movie Review Sentiment Analysis<H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Summary</H2>\n",
    "Note, this attempt at sentiment analysis is version 2 of our work.  The first version described what we are doing so wee will not repeat it here.\n",
    "\n",
    "So the below code is just the library imports and the code in the cell below that is just defining a funciton to read in the input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(trainOrTest, lowerCase):    \n",
    "    lines=[]\n",
    "    if trainOrTest == 'train':\n",
    "        dfTxt = pd.read_csv('moviesentiment/train.tsv', sep = '\\t')\n",
    "    elif trainOrTest == 'test':\n",
    "        dfTxt = pd.read_csv('moviesentiment/test.tsv', sep = '\\t')\n",
    "    else:\n",
    "        return 'error'    \n",
    "    \n",
    "    # we don't know the state of the imported data...shuffle to make sure it is random\n",
    "    if trainOrTest == 'train':\n",
    "        dfTxt = shuffle(dfTxt, random_state=42)\n",
    "    lines = dfTxt.Phrase\n",
    "    #lowercase the text to reduce size of matrices to improve memory and run times (hopefully) as we will have less unique strings\n",
    "    if lowerCase:\n",
    "        lines = [line.lower() for line in lines]\n",
    "    \n",
    "    if trainOrTest == 'train':\n",
    "        sents = dfTxt.Sentiment\n",
    "    else:\n",
    "        sents = None\n",
    "    return dfTxt, lines, sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Stem Words</H2>\n",
    "We will do some lemmatization to get down to the root words.  Note we want to do this before the next section, marking negative words as once we indentify in the text words that are negative with a \"_neg\" suffix, lemmatization won't work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StemWords(stemChoice, lines):\n",
    "    if stemChoice == 'porter':\n",
    "        stemmer = nltk.PorterStemmer()        \n",
    "    elif stemChoice == 'snowball':\n",
    "        stemmer = SnowballStemmer(\"english\" )        \n",
    "    else:\n",
    "        return 'error'    \n",
    "    stemmedLines = [([stemmer.stem(s) for s in line.split()]) for line in lines]\n",
    "    lines = ([' '.join(tup) for tup in stemmedLines])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Mark Negative Words</H2>\n",
    "Find words that are used in negative phrases, e.g., This is not a good movie.  The words between the negative word, 'not', and the end of the sentence are marked as negative, i.e., a_neg, good_neg, movie_neg.  Hopefully this will identify some common words that are used in negative phrases to identify the degree of negative, while also just plainly flagging sentences that are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark negative words \n",
    "def MarkNegative(lines):\n",
    "    lines = [mark_negation(line.split()) for line in lines]\n",
    "    lines = ([' '.join(tup) for tup in lines])\n",
    "    lines = pd.Series( (line for line in lines) )\n",
    "    return lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Create Train and Test Sets of Data</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose porter as stemmer first\n",
    "def CreateTrainTestData(lines, trainSize, testSize):\n",
    "    size = trainSize -testSize\n",
    "    trainLines = lines[:size]\n",
    "    testLines = lines[size:size+testSize]\n",
    "    trainSents = sents[:size]\n",
    "    testSents = sents[size:size+testSize]\n",
    "    return trainLines, testLines, trainSents, testSents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxt, lines, sents = LoadData('train')\n",
    "allLines = StemWords('porter', lines)\n",
    "allLines = MarkNegative(allLines)\n",
    "trainLines, testLines, trainSents, testSents = CreateTrainTestData(allLines, len(allLines), 5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Data Examination</H2>\n",
    "\n",
    "We see that the majority of the data is classified as 2 (or neutral) sentiment.  So the data is \"unbalanced\".  This will play into some of the items we try in developing a classifier as we proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "dfTxt.groupby('Sentiment').count().plot.bar(ylim=0)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Create PipeLine</H2>\n",
    "\n",
    "<H3>Create Features</H3>\n",
    "Use CountVectorizer to create features out of all the words in the text, basically a sparse matrix of term -> frequencies.  \n",
    "\n",
    "<H3>Use TfidfTransformer</H3>\n",
    "So question becomes, does this transformation into term frequencies, which is based on Inverse Document Frequency (IDF).  This is supposed to reduce the weight from longer documents as opposed to shorter documents, but based on how our text is constructed (each document is at most a sentence), not sure how much this will help.\n",
    "\n",
    "<H3>Train Using Multinomial Naive Bayes</H3>\n",
    "\n",
    "Note, the starting params are nothing special, we will examine how to tune those later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6002\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.19      0.28       231\n",
      "          1       0.54      0.35      0.43       901\n",
      "          2       0.63      0.86      0.73      2553\n",
      "          3       0.52      0.39      0.44      1045\n",
      "          4       0.53      0.17      0.26       270\n",
      "\n",
      "avg / total       0.58      0.60      0.57      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfNB = Pipeline([('vect', CountVectorizer(max_df = .75, ngram_range = (1,1), stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(alpha = 0.001)),\n",
    "])\n",
    "# print trainLines\n",
    "# print len(trainSents)\n",
    "# print len(testSents)\n",
    "clfNB = clfNB.fit(trainLines, trainSents)\n",
    "\n",
    "\n",
    "predicted = clfNB.predict(testLines)\n",
    "print np.mean(predicted == testSents)\n",
    "print(metrics.classification_report(testSents, predicted, target_names=['0','1','2','3','4'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Grid Search</H2>\n",
    "Let's use grid search and try to optimize hyperparameters.  \n",
    "\n",
    "Note, commented out so reruns don't spend an exceptional long time running this...note, best params are in comments below.  During development we used subsets of the data for initial tuning, but used complete data for my final tuning which takes quite a long time to execute\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'vect__ngram_range': [(1, 1), (1, 2),(1,3)],\n",
    "#                'vect__max_df': (0.3, 0.4,0.5,0.6,0.7,0.8),               \n",
    "#                'tfidf__use_idf': (True, False),\n",
    "#                'clf__alpha': (.1, .01, .001),}\n",
    "# gs = GridSearchCV(clf, parameters, n_jobs=6)\n",
    "# gs = gs.fit(trainLines, trainSents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6354627300410433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.1,\n",
       " 'tfidf__use_idf': False,\n",
       " 'vect__max_df': 0.3,\n",
       " 'vect__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print gs.best_score_\n",
    "# gs.best_params_\n",
    "\n",
    "\n",
    "#Best Results\n",
    "# {'clf__alpha': 0.1,\n",
    "#  'tfidf__use_idf': False,\n",
    "#  'vect__max_df': 0.4,\n",
    "#  'vect__ngram_range': (1, 3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Update to use optimized params</H2>\n",
    "\n",
    "We see we went up in accuracy over 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6514\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.43      0.45       231\n",
      "          1       0.58      0.51      0.54       901\n",
      "          2       0.73      0.80      0.76      2553\n",
      "          3       0.56      0.53      0.54      1045\n",
      "          4       0.50      0.39      0.44       270\n",
      "\n",
      "avg / total       0.64      0.65      0.65      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfNB = Pipeline([('vect', CountVectorizer(max_df = 0.3, ngram_range = (1,3), stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "                     ('clf', MultinomialNB(alpha = 0.1)),\n",
    "])\n",
    "clfNB = clfNB.fit(trainLines, trainSents)\n",
    "\n",
    "predicted = clfNB.predict(testLines)\n",
    "print np.mean(predicted == testSents)\n",
    "print(metrics.classification_report(testSents, predicted, target_names=['0','1','2','3','4'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Try a Different Tool</H2>\n",
    "\n",
    "Try using Stochastic Gradient Descent.  We will use the same params for the CountVectorizer and TfidfTransformer as we did above, and then after our initial run, we will try to tune them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.563\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.10      0.18       231\n",
      "          1       0.54      0.10      0.16       901\n",
      "          2       0.56      0.96      0.71      2553\n",
      "          3       0.54      0.21      0.30      1045\n",
      "          4       0.67      0.12      0.21       270\n",
      "\n",
      "avg / total       0.56      0.56      0.48      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# works  worse than naive bayes at this point\n",
    "clf_SGD = Pipeline([('vect', CountVectorizer(max_df = 0.5, ngram_range= (1,2), stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "                     ('clf_SGD', SGDClassifier(alpha = 0.0001, penalty = 'l2',  max_iter=1000, tol = .0001, random_state=42)),\n",
    "])\n",
    "clf_SGD = clf_SGD.fit(trainLines, trainSents)\n",
    "\n",
    "predicted = clf_SGD.predict(testLines)\n",
    "print(np.mean(predicted == testSents))\n",
    "print(metrics.classification_report(testSents, predicted, target_names=['0','1','2','3','4'] ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>GridSearch for SGD</H2>\n",
    "\n",
    "Note, again, commented out, so reruns don't take exceptional amounts of time.  Best params are in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'vect__ngram_range': [(1, 1), (1, 2),(1,3)],\n",
    "#                'vect__max_df': (0.2, 0.3,0.4,0.5,0.6),  \n",
    "#                'tfidf__use_idf': (True, False),\n",
    "#                'clf_SGD__alpha': (.0001, .00001),\n",
    "#                'clf_SGD__penalty': ('l2', 'elasticnet'),} \n",
    "          \n",
    "\n",
    "# gs_SGD = GridSearchCV(clf_SGD, parameters, n_jobs=6)\n",
    "# gs_SGD = gs_SGD.fit(trainLines, trainSents)              \n",
    " \n",
    "\n",
    "# # Best Params:\n",
    "# {'clf_SGD__alpha': 1e-05,\n",
    "#  'clf_SGD__penalty': 'l2',\n",
    "#  'tfidf__use_idf': False,\n",
    "#  'vect__max_df': 0.2,\n",
    "#  'vect__ngram_range': (1, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646491460346882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf_SGD__alpha': 1e-05,\n",
       " 'clf_SGD__penalty': 'l2',\n",
       " 'tfidf__use_idf': False,\n",
       " 'vect__max_df': 0.2,\n",
       " 'vect__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print gs_SGD.best_score_\n",
    "#gs_SGD.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.33      0.40       231\n",
      "          1       0.61      0.42      0.50       901\n",
      "          2       0.69      0.87      0.77      2553\n",
      "          3       0.58      0.47      0.52      1045\n",
      "          4       0.56      0.30      0.39       270\n",
      "\n",
      "avg / total       0.64      0.65      0.63      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfSGD = Pipeline([('vect', CountVectorizer(max_df = 0.2, ngram_range= (1,3), stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "                     ('clf_SGD', SGDClassifier(alpha = 0.00001, penalty = 'l2', max_iter=1000, \n",
    "                                               tol = .0001, random_state=42)),\n",
    "                                                       \n",
    "])\n",
    "clfSGD = clfSGD.fit(trainLines, trainSents)\n",
    "predicted = clfSGD.predict(testLines)\n",
    "print(np.mean(predicted == testSents))\n",
    "print(metrics.classification_report(testSents, predicted, target_names=['0','1','2','3','4'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Snowball Stemming</H2>\n",
    "Let's try a different stemmer and see if that improves things.\n",
    "\n",
    "Results were very slightly worse for Gradient Descent, but slightly better for Naive Bayes, but in either case results were minimally changed by adjustment of choice of stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "0.6524\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.42      0.44       231\n",
      "          1       0.58      0.51      0.54       901\n",
      "          2       0.73      0.80      0.76      2553\n",
      "          3       0.56      0.53      0.54      1045\n",
      "          4       0.51      0.40      0.45       270\n",
      "\n",
      "avg / total       0.64      0.65      0.65      5000\n",
      "\n",
      "SGD\n",
      "0.6488\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.32      0.39       231\n",
      "          1       0.60      0.42      0.49       901\n",
      "          2       0.69      0.87      0.77      2553\n",
      "          3       0.58      0.47      0.52      1045\n",
      "          4       0.57      0.30      0.39       270\n",
      "\n",
      "avg / total       0.63      0.65      0.63      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#snowball stemmer\n",
    "dfTxt, lines, sents = LoadData('train')\n",
    "allLines = StemWords('snowball', lines)\n",
    "allLines = MarkNegative(allLines)\n",
    "trainLines, testLines, trainSents, testSents = CreateTrainTestData(allLines, len(allLines), 5000)\n",
    "\n",
    "clfNB = clfNB.fit(trainLines, trainSents)\n",
    "predicted = clfNB.predict(testLines)\n",
    "print 'Naive Bayes:'\n",
    "print np.mean(predicted == testSents)\n",
    "print(metrics.classification_report(testSents, predicted, target_names=['0','1','2','3','4'] ))\n",
    "\n",
    "\n",
    "clfSGD = clfSGD.fit(trainLines, trainSents)\n",
    "predicted = clfSGD.predict(testLines)\n",
    "print 'SGD'\n",
    "print(np.mean(predicted == testSents))\n",
    "print(metrics.classification_report(testSents, predicted, target_names=['0','1','2','3','4'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compare Different Models performance</h2>\n",
    "\n",
    "We will compare to see if maybe we should try a different model all together.  This is not a perfect test as it is possible that a model that scores poorly, if it's hyper parameters are tuned, could conceivably be the best performer (even if not really likely).\n",
    "\n",
    "We see that the Structured Vector model performed best, so we will work with that to see if we can improve on the classifying performance we have done so far.\n",
    "\n",
    "Again as with other long running sections, this is commented out, and best results are in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer(sublinear_tf=True, max_df = .4, min_df = 50, norm='l2', use_idf = False, ngram_range=(1, 2), stop_words='english')\n",
    "# features = tfidf.fit_transform(trainLines).toarray()\n",
    "# models = [\n",
    "#     RandomForestClassifier(n_estimators=200, max_depth=10, random_state=0),\n",
    "#     LinearSVC(),\n",
    "#     MultinomialNB(alpha = 0.1),\n",
    "#     LogisticRegression(random_state=42),\n",
    "# ]\n",
    "\n",
    "\n",
    "# CV = 5\n",
    "# dfCV = pd.DataFrame(index=range(CV * len(models)))\n",
    "# entries = []\n",
    "# for model in models:\n",
    "#   model_name = model.__class__.__name__\n",
    "#   accuracies = cross_val_score(model, features, trainSents, scoring='accuracy', cv=CV, n_jobs=6)\n",
    "#   for fold_idx, accuracy in enumerate(accuracies):\n",
    "#     entries.append((model_name, fold_idx, accuracy))\n",
    "# dfCV = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                model_name  fold_idx  accuracy\n",
      "0   RandomForestClassifier         0  0.509879\n",
      "1   RandomForestClassifier         1  0.509880\n",
      "2   RandomForestClassifier         2  0.509947\n",
      "3   RandomForestClassifier         3  0.509947\n",
      "4   RandomForestClassifier         4  0.509930\n",
      "5                LinearSVC         0  0.617839\n",
      "6                LinearSVC         1  0.612021\n",
      "7                LinearSVC         2  0.609348\n",
      "8                LinearSVC         3  0.609679\n",
      "9                LinearSVC         4  0.612248\n",
      "10           MultinomialNB         0  0.576833\n",
      "11           MultinomialNB         1  0.573098\n",
      "12           MultinomialNB         2  0.573533\n",
      "13           MultinomialNB         3  0.569991\n",
      "14           MultinomialNB         4  0.573320\n",
      "15      LogisticRegression         0  0.614529\n",
      "16      LogisticRegression         1  0.608480\n",
      "17      LogisticRegression         2  0.606567\n",
      "18      LogisticRegression         3  0.606369\n",
      "19      LogisticRegression         4  0.609037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xef9f860>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print dfCV\n",
    "sns.boxplot(x='model_name', y='accuracy', data=dfCV)\n",
    "\n",
    "#                 model_name  fold_idx  accuracy\n",
    "# 0   RandomForestClassifier         0  0.509879\n",
    "# 1   RandomForestClassifier         1  0.509880\n",
    "# 2   RandomForestClassifier         2  0.509947\n",
    "# 3   RandomForestClassifier         3  0.509947\n",
    "# 4   RandomForestClassifier         4  0.509930\n",
    "# 5                LinearSVC         0  0.617839\n",
    "# 6                LinearSVC         1  0.612021\n",
    "# 7                LinearSVC         2  0.609348\n",
    "# 8                LinearSVC         3  0.609679\n",
    "# 9                LinearSVC         4  0.612248\n",
    "# 10           MultinomialNB         0  0.576833\n",
    "# 11           MultinomialNB         1  0.573098\n",
    "# 12           MultinomialNB         2  0.573533\n",
    "# 13           MultinomialNB         3  0.569991\n",
    "# 14           MultinomialNB         4  0.573320\n",
    "# 15      LogisticRegression         0  0.614529\n",
    "# 16      LogisticRegression         1  0.608480\n",
    "# 17      LogisticRegression         2  0.606567\n",
    "# 18      LogisticRegression         3  0.606369\n",
    "# 19      LogisticRegression         4  0.609037"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Tune the SVC Model</H2>\n",
    "\n",
    "Commented out as long running--best results in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfSVC = Pipeline([('vect', CountVectorizer(max_df = 0.3, ngram_range= (1,3), stop_words='english')),\n",
    "#                      ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "#                      ('clfSVC', LinearSVC(),)\n",
    "                                                       \n",
    "# ])\n",
    "# clfSVC = clfSVC.fit(trainLines, trainSents)\n",
    "\n",
    "# parameters = {'vect__ngram_range': [(1, 1), (1, 2),(1,3)],\n",
    "#                'vect__max_df': (0.3,0.4,0.5,0.6),  \n",
    "#                'tfidf__use_idf': (True, False),\n",
    "#                'clfSVC__loss': ('hinge', 'squared_hinge'),\n",
    "#                 'clfSVC__C': (0.5,0.75,1.0),}                             \n",
    "\n",
    "# gsSVC = GridSearchCV(clfSVC, parameters, n_jobs=6)\n",
    "# gsSVC = gsSVC.fit(trainLines, trainSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6542565867867073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clfSVC__C': 0.5,\n",
       " 'clfSVC__loss': 'squared_hinge',\n",
       " 'tfidf__use_idf': False,\n",
       " 'vect__max_df': 0.3,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print gsSVC.best_score_\n",
    "# gsSVC.best_params_\n",
    "\n",
    "# 0.6542565867867073\n",
    "# {'clfSVC__C': 0.5,\n",
    "#  'clfSVC__loss': 'squared_hinge',\n",
    "#  'tfidf__use_idf': False,\n",
    "#  'vect__max_df': 0.3,\n",
    "#  'vect__ngram_range': (1, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.34      0.40       231\n",
      "          1       0.59      0.49      0.54       901\n",
      "          2       0.72      0.84      0.78      2553\n",
      "          3       0.58      0.51      0.54      1045\n",
      "          4       0.53      0.36      0.43       270\n",
      "\n",
      "avg / total       0.65      0.66      0.65      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfSVC = Pipeline([('vect', CountVectorizer(max_df = 0.5, ngram_range= (1,2), stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "                     ('clfSVC', LinearSVC(loss='squared_hinge', C=0.5),)\n",
    "                                                       \n",
    "])\n",
    "\n",
    "dfTxt, lines, sents = LoadData('train')\n",
    "allLines = StemWords('snowball', lines)\n",
    "allLines = MarkNegative(allLines)\n",
    "trainLines, testLines, trainSents, testSents = CreateTrainTestData(allLines, len(allLines), 5000)\n",
    "\n",
    "clfSVC = clfSVC.fit(trainLines, trainSents)\n",
    "\n",
    "predicted = clfSVC.predict(testLines)\n",
    "\n",
    "print np.mean(predicted == testSents)\n",
    "print(metrics.classification_report(testSents, predicted, target_names=['0','1','2','3','4'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Stop Words</H2>\n",
    "\n",
    "One thing not yet tried is not using the \"stopwords\" param.  This takes out some commone words from the modeling (a, the, you, etc.) that generally wouldn't affect results of sentiment analysis.  But the way this data set is structured there are lot of one or two word lines to be analyzed, and some of the involve these stopwords.  So below we take it out, and see that we actually improve 1% to almost 67% accuracy, our best score yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6696\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.36      0.43       231\n",
      "          1       0.61      0.50      0.55       901\n",
      "          2       0.73      0.85      0.78      2553\n",
      "          3       0.59      0.52      0.55      1045\n",
      "          4       0.56      0.37      0.44       270\n",
      "\n",
      "avg / total       0.66      0.67      0.66      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfSVC = Pipeline([('vect', CountVectorizer(max_df = 0.5, ngram_range= (1,2))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "                     ('clfSVC', LinearSVC(loss='squared_hinge', C=0.5),)\n",
    "                                                       \n",
    "])\n",
    "\n",
    "clfSVC = clfSVC.fit(trainLines, trainSents)\n",
    "\n",
    "predicted = clfSVC.predict(testLines)\n",
    "\n",
    "print np.mean(predicted == testSents)\n",
    "print(metrics.classification_report(testSents, predicted, target_names=['0','1','2','3','4'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Further Examination, Confusion Matrix</H2>\n",
    "\n",
    "So we are 67%, but if we look at the classification report above, we see we do quite well comparatively to 2 or neutral sentiments, but we get noticably worse results as we move away from neutral.  \n",
    "\n",
    "So, let's dig a little deeper, using a confusion matrix heat map to see in better detail where the classifier has gone wrong.  With this while results are still not great, they actually look <b>much better</b>.  We are not classifying things that are really negative as really positive or vice-versa; mostly we are off by 1 classifier, e.g., something that should have been a 2 was predicted as 3, something that should have been a 1 was predicted as a 2.  Very few things were off by more than 1 (the heatmap was quite 'cold' for such cells).  The diagonal of the heat map is much hotter than the away from it, which is what we want.\n",
    "\n",
    "The other thing to note, is that for the most part we are underpredicting away from a neutral sentiment (2).  That is we prediced a 2, when it should have been a 1 or 3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(testSents, predicted)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Examination of Rows in Error</H2>\n",
    "\n",
    "Below are all the test rows where the predicted value does not match.  What is interesting, is some of the actual prediction values seem (in my mind) to be erroneous in of themselves.  For example, 153214, often fabul (which is likley stemmed from often fabulous) seems postive, and was predicted as such, yet the score was neutral at a 2.  Or more extreme, 153401, \"it visual hideous\" was scored a neutral 2, but is seems pretty negative and the prediction was 0.  \n",
    "\n",
    "So, it is possible some of the lack of success is due to items like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8717b67e8ec4fcf8f1a5ffc61c2b081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "UWdyaWRXaWRnZXQoZ3JpZF9vcHRpb25zPXsnaGlnaGxpZ2h0U2VsZWN0ZWRSb3cnOiBUcnVlLCAnZnVsbFdpZHRoUm93cyc6IFRydWUsICdyb3dIZWlnaHQnOiAyOCwgJ2VuYWJsZUNvbHVtblLigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import qgrid\n",
    "dfResults =  pd.DataFrame(data = {'sentence' : testLines , 'value': testSents.values, 'prediction': predicted})\n",
    "dfResults =  dfResults[['sentence', 'value', 'prediction'] ]\n",
    "dfResults['dif'] = dfResults.value - dfResults.prediction\n",
    "\n",
    "q = qgrid.show_grid(dfResults[dfResults.dif <> 0].sort_values(by='dif'), show_toolbar=False)\n",
    "q\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>NLTK Sentiment Intensity Analyzer</H2>\n",
    "One thought is that are learning methods above are using just supervised learning without any obvious knowledge of what words \"mean\".  So a consideration was done to use the SentimentIntensityAnalyzer which has a dictionary of words and their inherent postiveness or negativeness.  Since many predictions were off by one degree, the hope was that perhaps by adjusting predictions up or down for sentences that have high postiveness or negativeness, we could improve the accuracy a little bit.\n",
    "\n",
    "NLTK has a SentimentIntensityAnalyzer, perhaps by using this we can \"adjust\" scores a little bit for some that might be on the border, e.g., see that a 3 should really be a 2, b/c there is some negative phrasing in the sentence.\n",
    "\n",
    "Overall, results were worse, an example run is below, with adjusted scores.  A grid of results show how things were adjusted, and some were certainly adjusted in the right direction, others were then adjusted in the wrong direction.  Since we were able to improve things, it is possible that a more complex algorithm using this analyzer could return better results, but we will not use it for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\todddesktop\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.36      0.43       231\n",
      "          1       0.61      0.50      0.55       901\n",
      "          2       0.73      0.83      0.77      2553\n",
      "          3       0.55      0.48      0.51      1045\n",
      "          4       0.42      0.43      0.42       270\n",
      "\n",
      "avg / total       0.64      0.65      0.64      5000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "      <th>dif</th>\n",
       "      <th>adjScore</th>\n",
       "      <th>adjDif</th>\n",
       "      <th>adjFromPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151091</th>\n",
       "      <td>fair dispos</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154371</th>\n",
       "      <td>recommend</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154446</th>\n",
       "      <td>the rich perform</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154531</th>\n",
       "      <td>, comic relief</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154563</th>\n",
       "      <td>reason attract holiday contrapt</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154576</th>\n",
       "      <td>enjoy the film</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154601</th>\n",
       "      <td>a strong messag</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154620</th>\n",
       "      <td>scoop</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154363</th>\n",
       "      <td>the gift</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154633</th>\n",
       "      <td>a strong case</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154718</th>\n",
       "      <td>win ani honor</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154767</th>\n",
       "      <td>is like</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154903</th>\n",
       "      <td>but fun .</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154906</th>\n",
       "      <td>talent enough</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154918</th>\n",
       "      <td>win ani award</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155027</th>\n",
       "      <td>great power</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155071</th>\n",
       "      <td>raffish charm and pierc intellect</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154662</th>\n",
       "      <td>clever concept</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155086</th>\n",
       "      <td>more grace way</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154353</th>\n",
       "      <td>a dream</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154313</th>\n",
       "      <td>cgi alien and super hero</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153950</th>\n",
       "      <td>of cinema ' award</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153956</th>\n",
       "      <td>action hero day</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153991</th>\n",
       "      <td>more like to enjoy on a comput</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154016</th>\n",
       "      <td>better video-game-bas</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154035</th>\n",
       "      <td>wise , wizen</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154037</th>\n",
       "      <td>of special</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154040</th>\n",
       "      <td>you like</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154330</th>\n",
       "      <td>a clear sens</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154113</th>\n",
       "      <td>help</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153410</th>\n",
       "      <td>as a compliment</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153459</th>\n",
       "      <td>of humor</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153467</th>\n",
       "      <td>love and</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153624</th>\n",
       "      <td>the scenic splendor</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153667</th>\n",
       "      <td>good theatr</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153709</th>\n",
       "      <td>help</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153729</th>\n",
       "      <td>this fresh</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153744</th>\n",
       "      <td>a fine</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153448</th>\n",
       "      <td>are commend</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152419</th>\n",
       "      <td>love song</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153175</th>\n",
       "      <td>a casual intellig</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153093</th>\n",
       "      <td>charm</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152480</th>\n",
       "      <td>play well</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152490</th>\n",
       "      <td>good idea</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152495</th>\n",
       "      <td>good spirit</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152522</th>\n",
       "      <td>for a laugh</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152658</th>\n",
       "      <td>itself , a play spirit and</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152659</th>\n",
       "      <td>rich women</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152738</th>\n",
       "      <td>a perfect respect , perfect inoffens , easili forgett film .</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153145</th>\n",
       "      <td>music passion</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152768</th>\n",
       "      <td>genuin laugh</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152861</th>\n",
       "      <td>talent agent</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152895</th>\n",
       "      <td>stamina and</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152935</th>\n",
       "      <td>fond</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152959</th>\n",
       "      <td>, who care ?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153001</th>\n",
       "      <td>the best intent</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153070</th>\n",
       "      <td>like a siev</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153087</th>\n",
       "      <td>help herself</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152821</th>\n",
       "      <td>glorious straight from the vagina</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156029</th>\n",
       "      <td>enlighten , insight and entertain</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            sentence  value  \\\n",
       "151091                                                   fair dispos      0   \n",
       "154371                                                     recommend      3   \n",
       "154446                                              the rich perform      3   \n",
       "154531                                                , comic relief      2   \n",
       "154563                               reason attract holiday contrapt      3   \n",
       "154576                                                enjoy the film      3   \n",
       "154601                                               a strong messag      3   \n",
       "154620                                                         scoop      2   \n",
       "154363                                                      the gift      2   \n",
       "154633                                                 a strong case      3   \n",
       "154718                                                 win ani honor      2   \n",
       "154767                                                       is like      2   \n",
       "154903                                                     but fun .      3   \n",
       "154906                                                 talent enough      2   \n",
       "154918                                                 win ani award      2   \n",
       "155027                                                   great power      3   \n",
       "155071                             raffish charm and pierc intellect      2   \n",
       "154662                                                clever concept      3   \n",
       "155086                                                more grace way      3   \n",
       "154353                                                       a dream      2   \n",
       "154313                                      cgi alien and super hero      2   \n",
       "153950                                             of cinema ' award      3   \n",
       "153956                                               action hero day      2   \n",
       "153991                                more like to enjoy on a comput      2   \n",
       "154016                                         better video-game-bas      3   \n",
       "154035                                                  wise , wizen      3   \n",
       "154037                                                    of special      2   \n",
       "154040                                                      you like      2   \n",
       "154330                                                  a clear sens      2   \n",
       "154113                                                          help      3   \n",
       "...                                                              ...    ...   \n",
       "153410                                               as a compliment      3   \n",
       "153459                                                      of humor      2   \n",
       "153467                                                      love and      3   \n",
       "153624                                           the scenic splendor      4   \n",
       "153667                                                   good theatr      3   \n",
       "153709                                                          help      2   \n",
       "153729                                                    this fresh      2   \n",
       "153744                                                        a fine      2   \n",
       "153448                                                   are commend      2   \n",
       "152419                                                     love song      3   \n",
       "153175                                             a casual intellig      3   \n",
       "153093                                                         charm      3   \n",
       "152480                                                     play well      3   \n",
       "152490                                                     good idea      3   \n",
       "152495                                                   good spirit      4   \n",
       "152522                                                   for a laugh      3   \n",
       "152658                                    itself , a play spirit and      3   \n",
       "152659                                                    rich women      2   \n",
       "152738  a perfect respect , perfect inoffens , easili forgett film .      2   \n",
       "153145                                                 music passion      3   \n",
       "152768                                                  genuin laugh      4   \n",
       "152861                                                  talent agent      2   \n",
       "152895                                                   stamina and      2   \n",
       "152935                                                          fond      3   \n",
       "152959                                                  , who care ?      2   \n",
       "153001                                               the best intent      3   \n",
       "153070                                                   like a siev      2   \n",
       "153087                                                  help herself      2   \n",
       "152821                             glorious straight from the vagina      2   \n",
       "156029                             enlighten , insight and entertain      4   \n",
       "\n",
       "        prediction  dif  adjScore  adjDif  adjFromPred  \n",
       "151091           1   -1         2      -2           -1  \n",
       "154371           3    0         4      -1           -1  \n",
       "154446           3    0         4      -1           -1  \n",
       "154531           3   -1         4      -2           -1  \n",
       "154563           3    0         4      -1           -1  \n",
       "154576           3    0         4      -1           -1  \n",
       "154601           3    0         4      -1           -1  \n",
       "154620           2    0         3      -1           -1  \n",
       "154363           2    0         3      -1           -1  \n",
       "154633           3    0         4      -1           -1  \n",
       "154718           2    0         3      -1           -1  \n",
       "154767           2    0         3      -1           -1  \n",
       "154903           3    0         4      -1           -1  \n",
       "154906           3   -1         4      -2           -1  \n",
       "154918           3   -1         4      -2           -1  \n",
       "155027           3    0         4      -1           -1  \n",
       "155071           3   -1         4      -2           -1  \n",
       "154662           3    0         4      -1           -1  \n",
       "155086           3    0         4      -1           -1  \n",
       "154353           2    0         3      -1           -1  \n",
       "154313           2    0         3      -1           -1  \n",
       "153950           2    1         3       0           -1  \n",
       "153956           2    0         3      -1           -1  \n",
       "153991           2    0         3      -1           -1  \n",
       "154016           3    0         4      -1           -1  \n",
       "154035           3    0         4      -1           -1  \n",
       "154037           3   -1         4      -2           -1  \n",
       "154040           2    0         3      -1           -1  \n",
       "154330           2    0         3      -1           -1  \n",
       "154113           2    1         3       0           -1  \n",
       "...            ...  ...       ...     ...          ...  \n",
       "153410           3    0         4      -1           -1  \n",
       "153459           2    0         3      -1           -1  \n",
       "153467           3    0         4      -1           -1  \n",
       "153624           3    1         4       0           -1  \n",
       "153667           2    1         3       0           -1  \n",
       "153709           2    0         3      -1           -1  \n",
       "153729           3   -1         4      -2           -1  \n",
       "153744           3   -1         4      -2           -1  \n",
       "153448           2    0         3      -1           -1  \n",
       "152419           2    1         3       0           -1  \n",
       "153175           3    0         4      -1           -1  \n",
       "153093           3    0         4      -1           -1  \n",
       "152480           3    0         4      -1           -1  \n",
       "152490           3    0         4      -1           -1  \n",
       "152495           3    1         4       0           -1  \n",
       "152522           3    0         4      -1           -1  \n",
       "152658           3    0         4      -1           -1  \n",
       "152659           2    0         3      -1           -1  \n",
       "152738           3   -1         4      -2           -1  \n",
       "153145           3    0         4      -1           -1  \n",
       "152768           3    1         4       0           -1  \n",
       "152861           2    0         3      -1           -1  \n",
       "152895           2    0         3      -1           -1  \n",
       "152935           3    0         4      -1           -1  \n",
       "152959           2    0         3      -1           -1  \n",
       "153001           3    0         4      -1           -1  \n",
       "153070           2    0         3      -1           -1  \n",
       "153087           2    0         3      -1           -1  \n",
       "152821           2    0         3      -1           -1  \n",
       "156029           3    1         4       0           -1  \n",
       "\n",
       "[159 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "adjScores = []\n",
    "polaritys = []\n",
    "for idx, row in dfResults.iterrows():    \n",
    "    polarity = sid.polarity_scores(row.sentence)['pos'] - sid.polarity_scores(row.sentence)['neg'] \n",
    "    \n",
    "    if (float(polarity) > 0.6) and (row.prediction < 4):\n",
    "        adjScore = row.prediction + 1\n",
    "    elif (polarity < -1.6) and (row.prediction >0):\n",
    "        adjScore = row.prediction - 1        \n",
    "    else:\n",
    "         adjScore = row.prediction\n",
    "    adjScores.append(adjScore)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "dfResults['adjScore'] = adjScores\n",
    "dfResults['adjDif'] = dfResults.value - dfResults.adjScore\n",
    "dfResults['adjFromPred'] = dfResults.prediction - dfResults.adjScore\n",
    "print(metrics.classification_report(testSents, dfResults.adjScore, target_names=['0','1','2','3','4'] ))\n",
    "dfResults[dfResults.adjFromPred <> 0].sort_values(by='adjFromPred')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Probabilities</H2>\n",
    "\n",
    "One last thing tried is adjusting classification based on probabilities.  The theory is that perhaps if we examing probabilities algorithmically, we can tweak some scores up or down.  \n",
    "\n",
    "Since SVC doesn't support returning probabilities we will use the next best classifier from when we examined which performed best for this data, this would be just logistic regression.\n",
    "\n",
    "So first we will use GridSearch to optimize parameters (again commented out) to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainLines, testLines, trainSents, testSents = CreateTrainTestData(allLines, 25000, 5000)\n",
    "# clfLog = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('clfLog', LogisticRegression(random_state=42,multi_class='multinomial', solver = 'lbfgs'))\n",
    "                                                       \n",
    "# ])\n",
    "# clfLog = clfLog.fit(trainLines, trainSents)\n",
    "\n",
    "# parameters = {'vect__ngram_range': [(1, 1), (1, 2),(1,3), (1,4)],\n",
    "#                'vect__max_df': (0.2, 0.3, 0.4, 0.5, 0.6),  \n",
    "#                'tfidf__use_idf': (True, False),                             \n",
    "#                'clfLog__C': (0.25, 0.5, 0.75, 1.0,1.5,2.0,2.5,3.0),}               \n",
    "#                #'clfLog__penalty': ('l1', 'l2'),              \n",
    "\n",
    "# gsLog = GridSearchCV(clfLog, parameters, n_jobs=6)\n",
    "# gsLog = gsLog.fit(trainLines, trainSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clfLog__C': 2.0,\n",
       " 'tfidf__use_idf': False,\n",
       " 'vect__max_df': 0.2,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print gsLog.best_score_\n",
    "# gsLog.best_params_\n",
    "\n",
    "# 0.5711\n",
    "# {'clfLog__C': 2.0,\n",
    "#  'tfidf__use_idf': False,\n",
    "#  'vect__max_df': 0.2,\n",
    "#  'vect__ngram_range': (1, 2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Results of Tuning Logistic Regression Classifier</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.638\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.20      0.29       231\n",
      "          1       0.55      0.38      0.45       901\n",
      "          2       0.68      0.87      0.76      2553\n",
      "          3       0.57      0.49      0.52      1045\n",
      "          4       0.55      0.25      0.34       270\n",
      "\n",
      "avg / total       0.62      0.64      0.61      5000\n",
      "\n",
      "0  231  85\n",
      "1  901  626\n",
      "2  2553  3273\n",
      "3  1045  894\n",
      "4  270  122\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainLines, testLines, trainSents, testSents = CreateTrainTestData(allLines, len(allLines), 5000)\n",
    "\n",
    "\n",
    "clfLog = Pipeline([('vect', CountVectorizer(max_df = 0.2, ngram_range=(1,1))), # stop_words='english')),  #stopwords reduces accuracy\n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "                     ('clfLog', LogisticRegression(random_state=42, C=1.0, penalty= 'l2', multi_class='multinomial', solver = 'lbfgs')),                                                      \n",
    "])\n",
    "clfLog = clfLog.fit(trainLines, trainSents)\n",
    "predicted = clfLog.predict(testLines)\n",
    "print np.mean(predicted == testSents)\n",
    "print(metrics.classification_report(testSents, predicted, target_names=['0','1','2','3','4'] ))\n",
    "\n",
    "for sent in [0,1,2,3,4]:\n",
    "    print str(sent) + '  ' + str(len(testSents[testSents == sent])) + '  ' + str(len(predicted[predicted == sent]))\n",
    "    \n",
    "conf_mat = confusion_matrix(testSents, predicted)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Examination of the Probabilities</H2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S0</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.118147</td>\n",
       "      <td>0.518538</td>\n",
       "      <td>0.285241</td>\n",
       "      <td>0.069166</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.454517</td>\n",
       "      <td>0.455057</td>\n",
       "      <td>0.047592</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.090215</td>\n",
       "      <td>0.049909</td>\n",
       "      <td>0.638608</td>\n",
       "      <td>0.189106</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.312194</td>\n",
       "      <td>0.245238</td>\n",
       "      <td>0.188039</td>\n",
       "      <td>0.237662</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.589895</td>\n",
       "      <td>0.241050</td>\n",
       "      <td>0.040270</td>\n",
       "      <td>0.076306</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.020464</td>\n",
       "      <td>0.776658</td>\n",
       "      <td>0.166270</td>\n",
       "      <td>0.031096</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.014471</td>\n",
       "      <td>0.614247</td>\n",
       "      <td>0.256727</td>\n",
       "      <td>0.109273</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.059794</td>\n",
       "      <td>0.388727</td>\n",
       "      <td>0.411893</td>\n",
       "      <td>0.118428</td>\n",
       "      <td>0.021158</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.378940</td>\n",
       "      <td>0.408803</td>\n",
       "      <td>0.157104</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.014452</td>\n",
       "      <td>0.075523</td>\n",
       "      <td>0.163581</td>\n",
       "      <td>0.552557</td>\n",
       "      <td>0.193887</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.376965</td>\n",
       "      <td>0.193735</td>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.209342</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.694902</td>\n",
       "      <td>0.260887</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.030410</td>\n",
       "      <td>0.151419</td>\n",
       "      <td>0.390804</td>\n",
       "      <td>0.381180</td>\n",
       "      <td>0.046187</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.109741</td>\n",
       "      <td>0.348256</td>\n",
       "      <td>0.105190</td>\n",
       "      <td>0.349569</td>\n",
       "      <td>0.087243</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>0.087770</td>\n",
       "      <td>0.528685</td>\n",
       "      <td>0.366209</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.018233</td>\n",
       "      <td>0.075051</td>\n",
       "      <td>0.459657</td>\n",
       "      <td>0.418890</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.033718</td>\n",
       "      <td>0.042371</td>\n",
       "      <td>0.277498</td>\n",
       "      <td>0.515428</td>\n",
       "      <td>0.130985</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.014009</td>\n",
       "      <td>0.204029</td>\n",
       "      <td>0.336719</td>\n",
       "      <td>0.432041</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.048281</td>\n",
       "      <td>0.792591</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.036376</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.308455</td>\n",
       "      <td>0.580160</td>\n",
       "      <td>0.082339</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.036458</td>\n",
       "      <td>0.161269</td>\n",
       "      <td>0.370693</td>\n",
       "      <td>0.390382</td>\n",
       "      <td>0.041198</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.077175</td>\n",
       "      <td>0.557322</td>\n",
       "      <td>0.341330</td>\n",
       "      <td>0.020121</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.678292</td>\n",
       "      <td>0.313821</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.078788</td>\n",
       "      <td>0.448043</td>\n",
       "      <td>0.284753</td>\n",
       "      <td>0.157045</td>\n",
       "      <td>0.031372</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.079969</td>\n",
       "      <td>0.237386</td>\n",
       "      <td>0.204363</td>\n",
       "      <td>0.263396</td>\n",
       "      <td>0.214886</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.018895</td>\n",
       "      <td>0.041127</td>\n",
       "      <td>0.085724</td>\n",
       "      <td>0.649167</td>\n",
       "      <td>0.205087</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.004844</td>\n",
       "      <td>0.033499</td>\n",
       "      <td>0.117552</td>\n",
       "      <td>0.486825</td>\n",
       "      <td>0.357280</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.019658</td>\n",
       "      <td>0.510500</td>\n",
       "      <td>0.423163</td>\n",
       "      <td>0.044412</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.022903</td>\n",
       "      <td>0.100217</td>\n",
       "      <td>0.461031</td>\n",
       "      <td>0.354987</td>\n",
       "      <td>0.060863</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.023938</td>\n",
       "      <td>0.288277</td>\n",
       "      <td>0.460363</td>\n",
       "      <td>0.184155</td>\n",
       "      <td>0.043267</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>0.028032</td>\n",
       "      <td>0.104166</td>\n",
       "      <td>0.330355</td>\n",
       "      <td>0.511739</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>0.013275</td>\n",
       "      <td>0.044899</td>\n",
       "      <td>0.245944</td>\n",
       "      <td>0.570747</td>\n",
       "      <td>0.125135</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.271484</td>\n",
       "      <td>0.487316</td>\n",
       "      <td>0.171681</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>0.076995</td>\n",
       "      <td>0.400189</td>\n",
       "      <td>0.400242</td>\n",
       "      <td>0.114178</td>\n",
       "      <td>0.008396</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>0.040586</td>\n",
       "      <td>0.222236</td>\n",
       "      <td>0.111109</td>\n",
       "      <td>0.575828</td>\n",
       "      <td>0.050241</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>0.072630</td>\n",
       "      <td>0.481288</td>\n",
       "      <td>0.414575</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>0.056078</td>\n",
       "      <td>0.098624</td>\n",
       "      <td>0.480252</td>\n",
       "      <td>0.294032</td>\n",
       "      <td>0.071014</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>0.079161</td>\n",
       "      <td>0.126678</td>\n",
       "      <td>0.155459</td>\n",
       "      <td>0.424554</td>\n",
       "      <td>0.214148</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>0.406165</td>\n",
       "      <td>0.544373</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.027868</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.010781</td>\n",
       "      <td>0.059580</td>\n",
       "      <td>0.104741</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.134252</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.021034</td>\n",
       "      <td>0.445856</td>\n",
       "      <td>0.466920</td>\n",
       "      <td>0.064049</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.219670</td>\n",
       "      <td>0.388296</td>\n",
       "      <td>0.359489</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>0.020965</td>\n",
       "      <td>0.171355</td>\n",
       "      <td>0.447828</td>\n",
       "      <td>0.346661</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>0.016116</td>\n",
       "      <td>0.068538</td>\n",
       "      <td>0.445717</td>\n",
       "      <td>0.375799</td>\n",
       "      <td>0.093830</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>0.090693</td>\n",
       "      <td>0.475025</td>\n",
       "      <td>0.299965</td>\n",
       "      <td>0.107252</td>\n",
       "      <td>0.027066</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>0.013902</td>\n",
       "      <td>0.039242</td>\n",
       "      <td>0.097974</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.452330</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>0.027583</td>\n",
       "      <td>0.198717</td>\n",
       "      <td>0.311052</td>\n",
       "      <td>0.424948</td>\n",
       "      <td>0.037699</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>0.057081</td>\n",
       "      <td>0.560589</td>\n",
       "      <td>0.363131</td>\n",
       "      <td>0.016467</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>0.007565</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>0.257673</td>\n",
       "      <td>0.543765</td>\n",
       "      <td>0.130357</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>0.036381</td>\n",
       "      <td>0.109661</td>\n",
       "      <td>0.240324</td>\n",
       "      <td>0.490869</td>\n",
       "      <td>0.122766</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>0.013957</td>\n",
       "      <td>0.019415</td>\n",
       "      <td>0.204677</td>\n",
       "      <td>0.479751</td>\n",
       "      <td>0.282201</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>0.020218</td>\n",
       "      <td>0.582150</td>\n",
       "      <td>0.297591</td>\n",
       "      <td>0.095115</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>0.126283</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.170016</td>\n",
       "      <td>0.225683</td>\n",
       "      <td>0.042723</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.015594</td>\n",
       "      <td>0.052838</td>\n",
       "      <td>0.611292</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>0.060659</td>\n",
       "      <td>0.411744</td>\n",
       "      <td>0.473131</td>\n",
       "      <td>0.044769</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>0.295313</td>\n",
       "      <td>0.515481</td>\n",
       "      <td>0.059628</td>\n",
       "      <td>0.066353</td>\n",
       "      <td>0.063225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>0.031742</td>\n",
       "      <td>0.107807</td>\n",
       "      <td>0.259547</td>\n",
       "      <td>0.379910</td>\n",
       "      <td>0.220994</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.228459</td>\n",
       "      <td>0.663364</td>\n",
       "      <td>0.074620</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.049755</td>\n",
       "      <td>0.145269</td>\n",
       "      <td>0.445623</td>\n",
       "      <td>0.347182</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.189864</td>\n",
       "      <td>0.411079</td>\n",
       "      <td>0.149677</td>\n",
       "      <td>0.173886</td>\n",
       "      <td>0.075495</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            S0        S1        S2        S3        S4  Predicted  Actual\n",
       "5     0.118147  0.518538  0.285241  0.069166  0.008908          1       0\n",
       "11    0.036718  0.454517  0.455057  0.047592  0.006115          2       1\n",
       "13    0.032162  0.090215  0.049909  0.638608  0.189106          3       1\n",
       "15    0.312194  0.245238  0.188039  0.237662  0.016867          0       1\n",
       "16    0.589895  0.241050  0.040270  0.076306  0.052478          0       1\n",
       "19    0.020464  0.776658  0.166270  0.031096  0.005512          1       2\n",
       "31    0.014471  0.614247  0.256727  0.109273  0.005283          1       0\n",
       "41    0.059794  0.388727  0.411893  0.118428  0.021158          2       1\n",
       "51    0.027514  0.378940  0.408803  0.157104  0.027640          2       3\n",
       "56    0.014452  0.075523  0.163581  0.552557  0.193887          3       4\n",
       "57    0.376965  0.193735  0.207998  0.209342  0.011961          0       1\n",
       "58    0.007183  0.012939  0.024088  0.694902  0.260887          3       4\n",
       "61    0.030410  0.151419  0.390804  0.381180  0.046187          2       3\n",
       "62    0.109741  0.348256  0.105190  0.349569  0.087243          3       1\n",
       "65    0.008830  0.008507  0.087770  0.528685  0.366209          3       4\n",
       "73    0.018233  0.075051  0.459657  0.418890  0.028169          2       3\n",
       "74    0.033718  0.042371  0.277498  0.515428  0.130985          3       4\n",
       "91    0.014009  0.204029  0.336719  0.432041  0.013203          3       1\n",
       "92    0.048281  0.792591  0.115723  0.036376  0.007029          1       0\n",
       "102   0.005702  0.023345  0.308455  0.580160  0.082339          3       2\n",
       "109   0.036458  0.161269  0.370693  0.390382  0.041198          3       2\n",
       "112   0.077175  0.557322  0.341330  0.020121  0.004053          1       0\n",
       "114   0.001325  0.001660  0.004903  0.678292  0.313821          3       4\n",
       "116   0.078788  0.448043  0.284753  0.157045  0.031372          1       2\n",
       "117   0.079969  0.237386  0.204363  0.263396  0.214886          3       4\n",
       "118   0.018895  0.041127  0.085724  0.649167  0.205087          3       4\n",
       "131   0.004844  0.033499  0.117552  0.486825  0.357280          3       4\n",
       "133   0.019658  0.510500  0.423163  0.044412  0.002267          1       0\n",
       "138   0.022903  0.100217  0.461031  0.354987  0.060863          2       3\n",
       "139   0.023938  0.288277  0.460363  0.184155  0.043267          2       3\n",
       "...        ...       ...       ...       ...       ...        ...     ...\n",
       "4855  0.028032  0.104166  0.330355  0.511739  0.025708          3       2\n",
       "4860  0.013275  0.044899  0.245944  0.570747  0.125135          3       2\n",
       "4871  0.041395  0.271484  0.487316  0.171681  0.028125          2       1\n",
       "4873  0.076995  0.400189  0.400242  0.114178  0.008396          2       1\n",
       "4877  0.040586  0.222236  0.111109  0.575828  0.050241          3       2\n",
       "4883  0.002167  0.029341  0.072630  0.481288  0.414575          3       4\n",
       "4884  0.056078  0.098624  0.480252  0.294032  0.071014          2       1\n",
       "4886  0.079161  0.126678  0.155459  0.424554  0.214148          3       0\n",
       "4891  0.406165  0.544373  0.013956  0.027868  0.007638          1       2\n",
       "4894  0.010781  0.059580  0.104741  0.690647  0.134252          3       2\n",
       "4895  0.002142  0.021034  0.445856  0.466920  0.064049          3       2\n",
       "4897  0.005896  0.026649  0.219670  0.388296  0.359489          3       4\n",
       "4899  0.020965  0.171355  0.447828  0.346661  0.013191          2       3\n",
       "4905  0.016116  0.068538  0.445717  0.375799  0.093830          2       3\n",
       "4923  0.090693  0.475025  0.299965  0.107252  0.027066          1       3\n",
       "4928  0.013902  0.039242  0.097974  0.396552  0.452330          4       3\n",
       "4931  0.027583  0.198717  0.311052  0.424948  0.037699          3       2\n",
       "4932  0.057081  0.560589  0.363131  0.016467  0.002732          1       3\n",
       "4934  0.007565  0.060639  0.257673  0.543765  0.130357          3       2\n",
       "4941  0.036381  0.109661  0.240324  0.490869  0.122766          3       2\n",
       "4947  0.013957  0.019415  0.204677  0.479751  0.282201          3       4\n",
       "4950  0.020218  0.582150  0.297591  0.095115  0.004927          1       2\n",
       "4951  0.126283  0.435294  0.170016  0.225683  0.042723          1       2\n",
       "4969  0.003943  0.015594  0.052838  0.611292  0.316333          3       4\n",
       "4975  0.060659  0.411744  0.473131  0.044769  0.009698          2       1\n",
       "4983  0.295313  0.515481  0.059628  0.066353  0.063225          1       0\n",
       "4984  0.031742  0.107807  0.259547  0.379910  0.220994          3       2\n",
       "4996  0.012300  0.021256  0.228459  0.663364  0.074620          3       2\n",
       "4998  0.049755  0.145269  0.445623  0.347182  0.012170          2       3\n",
       "4999  0.189864  0.411079  0.149677  0.173886  0.075495          1       2\n",
       "\n",
       "[1054 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predProb = clfLog.predict_proba(testLines)\n",
    "predProb\n",
    "\n",
    "dfPred = pd.DataFrame(predProb)\n",
    "dfPred['Predicted'] = predicted\n",
    "dfPred['Actual'] = np.asarray(testSents)\n",
    "\n",
    "\n",
    "dfPred.columns = ['S0', 'S1', 'S2', 'S3', 'S4', 'Predicted', 'Actual'  ]\n",
    "dfPredOrig = dfPred.copy()\n",
    "dfPred[(dfPred.Predicted <> dfPred.Actual) & (dfPred['S2'] < 0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Results of Tweaking Predictions Based on Probability</H2>\n",
    "While playing with it a little bit we were able to increase the score about a quarter of a percent.  Not much but interesting nonetheless.  Regardless, these scores are still less than just using the SVC method and even with more tweaking to adjust items at 1 or 3 probabilites (the next most mislabled predictions) it is unlikely we will best that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPred = dfPredOrig.copy()\n",
    "\n",
    "for i in range(len(dfPred)):\n",
    "#     if (dfPred.Predicted[i] == 2) & (((dfPred.at[i,'S3'] + dfPred.at[i,'S4']) -.15  ) > dfPred.at[i,'S2']):        \n",
    "#         dfPred.at[i, 'Predicted'] = 3    \n",
    "    if (dfPred.Predicted[i] == 2) & (((dfPred.at[i,'S0'] + dfPred.at[i,'S1']) +.15  ) > dfPred.at[i,'S2']):            \n",
    "        dfPred.at[i, 'Predicted'] = 1\n",
    "        \n",
    "print np.mean(dfPred.Predicted == dfPred.Actual)\n",
    "print(metrics.classification_report(dfPred.Actual, dfPred.Predicted, target_names=['0','1','2','3','4'] ))\n",
    "            \n",
    "for sent in [0,1,2,3,4]:\n",
    "    print str(sent) + '  ' + str(len(dfPred.Actual[dfPred.Actual == sent])) + '  ' + str(len(dfPred.Predicted[dfPred.Predicted == sent]))\n",
    "    \n",
    "conf_mat = confusion_matrix(dfPred.Actual, dfPred.Predicted)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Running without lowercasing the text</H2>\n",
    "Initially we had lowercased all the text, so as to improve performance as we tested.  Before we are completely done, we will instead run the SVC classifier with the unadultered capitalization to get the best possible results.  It seems likely that there are cases were text is capitalized for emphasis, which could adjust sentiment.  A\n",
    "\n",
    "In doing this we see that we got about 1% more accuracy out of the model.  So it does indeed improve things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6696\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.36      0.43       231\n",
      "          1       0.61      0.50      0.55       901\n",
      "          2       0.73      0.85      0.78      2553\n",
      "          3       0.59      0.52      0.55      1045\n",
      "          4       0.56      0.37      0.44       270\n",
      "\n",
      "avg / total       0.66      0.67      0.66      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfTxt, lines, sents = LoadData('train', False)\n",
    "allLines = StemWords('snowball', lines)\n",
    "allLines = MarkNegative(allLines)\n",
    "trainLines, testLines, trainSents, testSents = CreateTrainTestData(allLines, len(allLines), 5000)\n",
    "\n",
    "clfSVC = Pipeline([('vect', CountVectorizer(max_df = 0.5, ngram_range= (1,2))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)),\n",
    "                     ('clfSVC', LinearSVC(loss='squared_hinge', C=0.5),)\n",
    "                                                       \n",
    "])\n",
    "\n",
    "clfSVC = clfSVC.fit(trainLines, trainSents)\n",
    "\n",
    "predicted = clfSVC.predict(testLines)\n",
    "\n",
    "print np.mean(predicted == testSents)\n",
    "print(metrics.classification_report(testSents, predicted, target_names=['0','1','2','3','4'] ))\n",
    "\n",
    "\n",
    "# 0.6696\n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#           0       0.52      0.36      0.43       231\n",
    "#           1       0.61      0.50      0.55       901\n",
    "#           2       0.73      0.85      0.78      2553\n",
    "#           3       0.59      0.52      0.55      1045\n",
    "#           4       0.56      0.37      0.44       270\n",
    "\n",
    "# avg / total       0.66      0.67      0.66      5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Submit on Kaggle, See how we did,</H2>\n",
    "The below will run the training on the whole train dataset (rather than most of it, since some was split of to evaluate for training).  It will then create a submission file for Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#retrain on the whole set of data, rather than the slightly incomplete set that reserved some for testing\n",
    "dfTxt, lines, sents = LoadData('train', False)\n",
    "allLines = StemWords('snowball', lines)\n",
    "allLines = MarkNegative(allLines)\n",
    "clfSVC = clfSVC.fit(allLines, dfTxt.Sentiment)\n",
    "#clfNB = clfNB.fit(allLines, dfTxt.Sentiment)\n",
    "\n",
    "dfTest, lines, sents = LoadData('test', False)\n",
    "allLines = StemWords('snowball', lines)\n",
    "allLines = MarkNegative(allLines)\n",
    "\n",
    "\n",
    "predicted = clfSVC.predict(allLines)\n",
    "dfTest['Sentiment']  = predicted\n",
    "\n",
    "\n",
    "dfSubmission = dfTest[['PhraseId', 'Sentiment']]\n",
    "dfSubmission.to_csv('moviesentiment/submission.csv', sep = ',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Results</H2>\n",
    "<img src=\"moviesentiment/kaggleSubmission.PNG\">\n",
    "Our score was about 63%, which was less than what we tested with.  So slightly disappointing, it may mean we overfitted some and should have worked more to address that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Comparison to Others</H2>\n",
    "If we compare our results to others we see our score of 0.63277, would have finished 224 out of 861, which is about at the 25% percentile from the top.  Also if looking at the complete leaderboard, only 5 people finished at 0.68 or higher.   So overall not too bad.  (Note because the competition is old, and closed, my submission did not get put onto the leaderboard)\n",
    "\n",
    "<img src=\"moviesentiment/kaggleLeaderBoard.PNG\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
